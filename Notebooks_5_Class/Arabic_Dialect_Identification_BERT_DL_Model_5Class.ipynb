{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Arabic Dialect Identification - Applying Machine Learning\n",
    "## By Karim Elshetihy\n",
    "- [Github](https://github.com/KarimElshetihy)\n",
    "- [Linkedin](https://www.linkedin.com/in/karim-el-shetihy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic Dialect Identification - Applying Deep Learning\n",
    "## By Karim Elshetihy\n",
    "- [Github](https://github.com/KarimElshetihy)\n",
    "- [Linkedin](https://www.linkedin.com/in/karim-el-shetihy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Referances:\n",
    "- [Arabic Dialict Identification in the Wild Paper](https://arxiv.org/pdf/2005.06557.pdf)\n",
    "- [Flask Tutorial](https://programminghistorian.org/en/lessons/creating-apis-with-python-and-flask)\n",
    "- [Multinomial Classification](https://towardsdatascience.com/the-complete-guide-to-neural-networks-multinomial-classification-4fe88bde7839)\n",
    "- [Multi-class text classification model with Keras](https://www.design-ai.de/blog-posts/multi-class-text-classification-model-with-keras)\n",
    "- [Word Embedding and Text Vectorization](https://www.analyticsvidhya.com/blog/2021/06/part-5-step-by-step-guide-to-master-nlp-text-vectorization-approaches/)\n",
    "\n",
    "\n",
    "#### The Dataset:\n",
    "The dataset and the dialect identification problem were addressed by Qatar Computing Research Institute, moreover, they published a paper, feel free to get more insights from it [Here](https://arxiv.org/pdf/2005.06557.pdf).\n",
    "\n",
    "We are given a dataset which has 2 columns, **id** and **dialect**.\n",
    "- Target label column is the **dialect***, which has 18 classes.\n",
    "- The **id** column will be used to retrieve the text, to do that, you need to call this API by a\n",
    "POST request. https://recruitment.aimtechnologies.co/ai-tasks.\n",
    "- The request body must be a JSON as a list of strings, and the size of the list must NOT exceed 1000.\n",
    "- The API will return a dictionary where the keys are the ids, and the values are the text, here is a request and response sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T14:41:21.295539Z",
     "iopub.status.busy": "2022-03-14T14:41:21.295176Z",
     "iopub.status.idle": "2022-03-14T14:41:29.982403Z",
     "shell.execute_reply": "2022-03-14T14:41:29.981295Z",
     "shell.execute_reply.started": "2022-03-14T14:41:21.295454Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sb\n",
    "\n",
    "import torch\n",
    "import torch , optuna, gc, random, os\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
    "from transformers import Trainer , TrainingArguments\n",
    "from transformers.trainer_utils import EvaluationStrategy\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
    "\n",
    "np.random.seed(1)\n",
    "%matplotlib inline\n",
    "sb.set_theme()\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Importing the Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T14:41:29.984915Z",
     "iopub.status.busy": "2022-03-14T14:41:29.984544Z",
     "iopub.status.idle": "2022-03-14T14:42:47.086576Z",
     "shell.execute_reply": "2022-03-14T14:42:47.085464Z",
     "shell.execute_reply.started": "2022-03-14T14:41:29.984855Z"
    }
   },
   "outputs": [],
   "source": [
    "#Setup Gdrive file download extention \n",
    "!conda install -y gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T14:42:47.089973Z",
     "iopub.status.busy": "2022-03-14T14:42:47.089411Z",
     "iopub.status.idle": "2022-03-14T14:42:51.450738Z",
     "shell.execute_reply": "2022-03-14T14:42:51.449399Z",
     "shell.execute_reply.started": "2022-03-14T14:42:47.089924Z"
    }
   },
   "outputs": [],
   "source": [
    "!gdown --id 1EnyzWLwO7fNF0eLAgvN9eXVOxOZgvn0k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T14:45:11.921335Z",
     "iopub.status.busy": "2022-03-14T14:45:11.920900Z",
     "iopub.status.idle": "2022-03-14T14:45:13.219273Z",
     "shell.execute_reply": "2022-03-14T14:45:13.218201Z",
     "shell.execute_reply.started": "2022-03-14T14:45:11.921286Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv(\"./5_class_dialects.csv\")\n",
    "df = clean_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T14:45:13.659963Z",
     "iopub.status.busy": "2022-03-14T14:45:13.659666Z",
     "iopub.status.idle": "2022-03-14T14:45:13.684220Z",
     "shell.execute_reply": "2022-03-14T14:45:13.683211Z",
     "shell.execute_reply.started": "2022-03-14T14:45:13.659929Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T14:45:28.181602Z",
     "iopub.status.busy": "2022-03-14T14:45:28.180997Z",
     "iopub.status.idle": "2022-03-14T14:45:28.307951Z",
     "shell.execute_reply": "2022-03-14T14:45:28.306236Z",
     "shell.execute_reply.started": "2022-03-14T14:45:28.181566Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure we running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T14:45:35.064266Z",
     "iopub.status.busy": "2022-03-14T14:45:35.063384Z",
     "iopub.status.idle": "2022-03-14T14:45:35.098937Z",
     "shell.execute_reply": "2022-03-14T14:45:35.097684Z",
     "shell.execute_reply.started": "2022-03-14T14:45:35.064229Z"
    }
   },
   "outputs": [],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    # !nvidia-smi\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T14:45:40.046486Z",
     "iopub.status.busy": "2022-03-14T14:45:40.046187Z",
     "iopub.status.idle": "2022-03-14T14:45:40.152930Z",
     "shell.execute_reply": "2022-03-14T14:45:40.151929Z",
     "shell.execute_reply.started": "2022-03-14T14:45:40.046452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare Train & Test Data\n",
    "test_data_size = 0.25\n",
    "train_test_ratio = int((1-test_data_size)*len(df))\n",
    "\n",
    "train_data = df[df.columns[-20:]][:train_test_ratio]\n",
    "test_data = df[df.columns[-20:]][train_test_ratio:]\n",
    "train_set, evaluation_set = train_test_split(train_data, test_size= 0.05, random_state= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying BERT Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T14:46:00.259308Z",
     "iopub.status.busy": "2022-03-14T14:46:00.258935Z",
     "iopub.status.idle": "2022-03-14T14:46:00.266055Z",
     "shell.execute_reply": "2022-03-14T14:46:00.264912Z",
     "shell.execute_reply.started": "2022-03-14T14:46:00.259256Z"
    }
   },
   "outputs": [],
   "source": [
    "# First setting the max_len , will be useful later for BERT Model\n",
    "Extra_Len = 6 # an extra padding in length , found to be useful for increasing F-score\n",
    "Max_Len = 128\n",
    "print(Max_Len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T14:46:00.581065Z",
     "iopub.status.busy": "2022-03-14T14:46:00.578993Z",
     "iopub.status.idle": "2022-03-14T14:46:00.598161Z",
     "shell.execute_reply": "2022-03-14T14:46:00.596724Z",
     "shell.execute_reply.started": "2022-03-14T14:46:00.581014Z"
    }
   },
   "outputs": [],
   "source": [
    "Model_Used = \"UBC-NLP/MARBERT\"\n",
    "Task_Name = \"classification\"\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, name, train, test, label_list,):\n",
    "        self.name = name\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.label_list = label_list\n",
    "        \n",
    "class BERTModelDataset(Dataset):\n",
    "    def __init__(self, text, target, model_name, max_len, label_map):\n",
    "        super(BERTModelDataset).__init__()\n",
    "        self.text = text\n",
    "        self.target = target\n",
    "        self.tokenizer_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.max_len = max_len\n",
    "        self.label_map = label_map\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        text = str(self.text[item])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        encoded_review = self.tokenizer.encode_plus(\n",
    "        text,\n",
    "        max_length= self.max_len,\n",
    "        add_special_tokens= True,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        truncation='longest_first',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoded_review['input_ids'].to(device)\n",
    "        attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "        return InputFeatures(input_ids=input_ids.flatten(), attention_mask=attention_mask.flatten(), label=self.label_map[self.target[item]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intializing the Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T14:46:01.117722Z",
     "iopub.status.busy": "2022-03-14T14:46:01.117421Z",
     "iopub.status.idle": "2022-03-14T14:46:01.131212Z",
     "shell.execute_reply": "2022-03-14T14:46:01.129762Z",
     "shell.execute_reply.started": "2022-03-14T14:46:01.117689Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(Model_Used, return_dict=True, num_labels=len(label_map))\n",
    "\n",
    "def compute_metrics(p): #p should be of type EvalPrediction\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    assert len(preds) == len(p.label_ids)\n",
    "    print(classification_report(p.label_ids,preds))\n",
    "    #print(confusion_matrix(p.label_ids,preds))\n",
    "\n",
    "    macro_f1_pos_neg = f1_score(p.label_ids,preds,average='macro',labels=[1,2])\n",
    "    macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
    "    macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
    "    macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
    "    acc = accuracy_score(p.label_ids,preds)\n",
    "    return {\n",
    "      'macro_f1' : macro_f1,\n",
    "      'macro_f1_pos_neg' : macro_f1_pos_neg,  \n",
    "      'macro_precision': macro_precision,\n",
    "      'macro_recall': macro_recall,\n",
    "      'accuracy': acc\n",
    "    }\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying BERT Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T14:46:12.254669Z",
     "iopub.status.busy": "2022-03-14T14:46:12.253780Z",
     "iopub.status.idle": "2022-03-14T14:46:26.855361Z",
     "shell.execute_reply": "2022-03-14T14:46:26.854227Z",
     "shell.execute_reply.started": "2022-03-14T14:46:12.254615Z"
    }
   },
   "outputs": [],
   "source": [
    "label_list = list(train_set['dialect'].unique())\n",
    "\n",
    "print(label_list)\n",
    "print(train_set['dialect'].value_counts())\n",
    "\n",
    "data_set = Dataset(\"KAUST\", train_set, evaluation_set, label_list)\n",
    "\n",
    "label_map = {v:index for index, v in enumerate(label_list) }\n",
    "print(label_map)\n",
    "\n",
    "train_dataset = BERTModelDataset(train_set['text'].to_list(),\n",
    "                                 train_set['dialect'].to_list(),\n",
    "                                 Model_Used,\n",
    "                                 Max_Len,\n",
    "                                 label_map)\n",
    "\n",
    "evaluation_dataset = BERTModelDataset(evaluation_set['text'].to_list(),\n",
    "                                      evaluation_set['dialect'].to_list(),\n",
    "                                      Model_Used,\n",
    "                                      Max_Len,\n",
    "                                      label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying BERT Model Training Arguments & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T14:47:20.471592Z",
     "iopub.status.busy": "2022-03-14T14:47:20.471266Z",
     "iopub.status.idle": "2022-03-14T14:47:20.488214Z",
     "shell.execute_reply": "2022-03-14T14:47:20.487065Z",
     "shell.execute_reply.started": "2022-03-14T14:47:20.471544Z"
    }
   },
   "outputs": [],
   "source": [
    "#define training arguments\n",
    "training_args = TrainingArguments(\"./train\")\n",
    "training_args.lr_scheduler_type = 'cosine'\n",
    "training_args.evaluate_during_training = True\n",
    "training_args.adam_epsilon =1e-8 \n",
    "Use_Train_Extended_Data = True\n",
    "\n",
    "if Use_Train_Extended_Data :\n",
    "    training_args.learning_rate = 1.215e-05 # use this with extended data\n",
    "else:\n",
    "    training_args.learning_rate = 1.78255000000000001e-05 # use this with org data  \n",
    "\n",
    "\n",
    "training_args.fp16 = True\n",
    "training_args.per_device_train_batch_size = 32 #64 \n",
    "training_args.per_device_eval_batch_size = 32 # 64 \n",
    "training_args.gradient_accumulation_steps = 2\n",
    "training_args.num_train_epochs= 2\n",
    "training_args.warmup_steps = 0 \n",
    "training_args.evaluation_strategy = 'steps'\n",
    "training_args.logging_steps = 1000\n",
    "training_args.save_steps = 8000 \n",
    "training_args.seed = 42 \n",
    "training_args.disable_tqdm = False\n",
    "training_args.output_dir='./results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T14:47:21.064607Z",
     "iopub.status.busy": "2022-03-14T14:47:21.064024Z",
     "iopub.status.idle": "2022-03-14T14:47:54.098797Z",
     "shell.execute_reply": "2022-03-14T14:47:54.097652Z",
     "shell.execute_reply.started": "2022-03-14T14:47:21.064554Z"
    }
   },
   "outputs": [],
   "source": [
    "Rand_Seed = 42\n",
    "training_args.dataloader_pin_memory = False\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "set_seed(Rand_Seed) \n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model_init(),\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset= evaluation_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T14:47:54.101873Z",
     "iopub.status.busy": "2022-03-14T14:47:54.101411Z",
     "iopub.status.idle": "2022-03-14T14:47:54.115051Z",
     "shell.execute_reply": "2022-03-14T14:47:54.113842Z",
     "shell.execute_reply.started": "2022-03-14T14:47:54.101825Z"
    }
   },
   "outputs": [],
   "source": [
    "print(training_args.seed)\n",
    "print(Max_Len)\n",
    "print(training_args.learning_rate)\n",
    "print(training_args.adam_epsilon)\n",
    "print(training_args.warmup_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T14:48:03.254967Z",
     "iopub.status.busy": "2022-03-14T14:48:03.254045Z",
     "iopub.status.idle": "2022-03-14T17:11:33.907343Z",
     "shell.execute_reply": "2022-03-14T17:11:33.906345Z",
     "shell.execute_reply.started": "2022-03-14T14:48:03.254915Z"
    }
   },
   "outputs": [],
   "source": [
    "#wandbkey if needed (depend on the transformers package version) = 0a58b374c46a154de1ba77c8634c6be279a9dcdb\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T17:11:33.910717Z",
     "iopub.status.busy": "2022-03-14T17:11:33.910046Z",
     "iopub.status.idle": "2022-03-14T17:12:57.205881Z",
     "shell.execute_reply": "2022-03-14T17:12:57.204945Z",
     "shell.execute_reply.started": "2022-03-14T17:11:33.910668Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:54:57.362997Z",
     "iopub.status.busy": "2022-03-14T17:54:57.362674Z",
     "iopub.status.idle": "2022-03-14T17:55:05.826357Z",
     "shell.execute_reply": "2022-03-14T17:55:05.825051Z",
     "shell.execute_reply.started": "2022-03-14T17:54:57.362963Z"
    }
   },
   "outputs": [],
   "source": [
    "# saving the fine tuned model & tokenizer\n",
    "model_path = \"./models/BERT_model\"\n",
    "trainer.model.save_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(Model_Used)\n",
    "tokenizer.save_pretrained(\"./models/tokenizer/\")\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained(\"./models/tokenizer/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Predictor(Prediction Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T17:17:30.982940Z",
     "iopub.status.busy": "2022-03-14T17:17:30.982594Z",
     "iopub.status.idle": "2022-03-14T17:47:55.101777Z",
     "shell.execute_reply": "2022-03-14T17:47:55.100811Z",
     "shell.execute_reply.started": "2022-03-14T17:17:30.982895Z"
    }
   },
   "outputs": [],
   "source": [
    "# first define the predection method\n",
    "def predict(text, tokenizer):\n",
    " \n",
    "    encoded_review = tokenizer.encode_plus(\n",
    "                                        text,\n",
    "                                        max_length=Max_Len,\n",
    "                                        add_special_tokens=True,\n",
    "                                        return_token_type_ids=False,\n",
    "                                        pad_to_max_length=True, #True,\n",
    "                                        truncation='longest_first',\n",
    "                                        return_attention_mask=True,\n",
    "                                        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoded_review['input_ids'].to(device) #(input_ids + ([tokenizer.pad_token_id] * padding_length)).to(device)  \n",
    "    attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "\n",
    "    output = trainer.model(input_ids, attention_mask)\n",
    "    _, prediction = torch.max(output[0], dim=1)\n",
    "    return prediction[0]\n",
    "\n",
    "#then lets play !\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(Model_Used)\n",
    "\n",
    "prediction_list = []\n",
    "for num, text in enumerate(test_data['text']):\n",
    "    if num > len(test_data['text']):\n",
    "        break\n",
    "    try:\n",
    "        id = test_data['id'][train_test_ratio+num]\n",
    "    except:\n",
    "        id = test_data['id'][-1]\n",
    "  \n",
    "    pre = predict(text,tokenizer)\n",
    "    pre_txt = label_list[pre]\n",
    "   \n",
    "#     if pre_txt == 'positive': pre_txt = 1\n",
    "#     if pre_txt == 'negative': pre_txt = -1\n",
    "#     if pre_txt == 'neutral': pre_txt = 0\n",
    "    prediction_list.append(pre_txt)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T17:47:55.103986Z",
     "iopub.status.busy": "2022-03-14T17:47:55.103665Z",
     "iopub.status.idle": "2022-03-14T17:47:55.258994Z",
     "shell.execute_reply": "2022-03-14T17:47:55.257980Z",
     "shell.execute_reply.started": "2022-03-14T17:47:55.103940Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(prediction_list)\n",
    "results = pd.DataFrame({'id' : test_data['id'].astype(str), 'Prediction' : prediction_list, 'True' : test_data['dialect']},\n",
    "                       columns = ['id', 'Prediction', 'True'])\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:47:55.261339Z",
     "iopub.status.busy": "2022-03-14T17:47:55.260949Z",
     "iopub.status.idle": "2022-03-14T17:47:55.561558Z",
     "shell.execute_reply": "2022-03-14T17:47:55.560501Z",
     "shell.execute_reply.started": "2022-03-14T17:47:55.261289Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(r'/kaggle/working')\n",
    "result_file = \"5_class_results.csv\"\n",
    "results.to_csv(result_file, sep= \",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-03-14T17:47:55.564177Z",
     "iopub.status.busy": "2022-03-14T17:47:55.563864Z",
     "iopub.status.idle": "2022-03-14T17:48:00.934757Z",
     "shell.execute_reply": "2022-03-14T17:48:00.933746Z",
     "shell.execute_reply.started": "2022-03-14T17:47:55.564108Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(results['True'], results['Prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing some Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:48:00.936952Z",
     "iopub.status.busy": "2022-03-14T17:48:00.936624Z",
     "iopub.status.idle": "2022-03-14T17:48:07.076062Z",
     "shell.execute_reply": "2022-03-14T17:48:07.075075Z",
     "shell.execute_reply.started": "2022-03-14T17:48:00.936895Z"
    }
   },
   "outputs": [],
   "source": [
    "BERT_5_CR = classification_report(results['True'], results['Prediction'], output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:48:07.083843Z",
     "iopub.status.busy": "2022-03-14T17:48:07.081445Z",
     "iopub.status.idle": "2022-03-14T17:48:07.586223Z",
     "shell.execute_reply": "2022-03-14T17:48:07.585106Z",
     "shell.execute_reply.started": "2022-03-14T17:48:07.083769Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8));\n",
    "sb.heatmap(pd.DataFrame(BERT_5_CR).iloc[:-1, :].T, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
